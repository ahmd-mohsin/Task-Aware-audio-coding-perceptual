{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(base_path):\n",
    "    \"\"\"Create output directory for spectrograms if it doesn't exist.\"\"\"\n",
    "    output_dir = os.path.join(base_path, 'spectrograms_S02_P05')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def load_audio_chunk(file_path, start_time, chunk_duration):\n",
    "    \"\"\"Load a chunk of audio from the file.\"\"\"\n",
    "    y, sr = librosa.load(file_path, offset=start_time, duration=chunk_duration)\n",
    "    return y, sr\n",
    "\n",
    "def create_spectrogram(y, sr, output_path):\n",
    "    \"\"\"Create and save a spectrogram for the given audio chunk.\"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Create spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    librosa.display.specshow(D, y_axis='log', x_axis='time', sr=sr)\n",
    "    \n",
    "    # Add colorbar and labels\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and close\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def process_audio_file(input_file, chunk_duration=30):\n",
    "    \"\"\"\n",
    "    Process a long audio file into spectrograms.\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): Path to input WAV file\n",
    "    chunk_duration (int): Duration of each chunk in seconds (default: 30)\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    base_path = os.path.dirname(input_file)\n",
    "    output_dir = create_output_directory(base_path)\n",
    "    \n",
    "    # Get total duration of the audio file\n",
    "    duration = librosa.get_duration(path=input_file)\n",
    "    total_chunks = int(np.ceil(duration / chunk_duration))\n",
    "    \n",
    "    print(f\"Total duration: {duration:.2f} seconds\")\n",
    "    print(f\"Number of chunks: {total_chunks}\")\n",
    "    \n",
    "    # Process each chunk\n",
    "    for chunk_idx in range(total_chunks):\n",
    "        start_time = chunk_idx * chunk_duration\n",
    "        \n",
    "        # Load audio chunk\n",
    "        try:\n",
    "            y, sr = load_audio_chunk(input_file, start_time, chunk_duration)\n",
    "            \n",
    "            # Generate output filename\n",
    "            output_path = os.path.join(\n",
    "                output_dir, \n",
    "                f'spectrogram_chunk_{chunk_idx:04d}.png'\n",
    "            )\n",
    "            \n",
    "            # Create and save spectrogram\n",
    "            create_spectrogram(y, sr, output_path)\n",
    "            \n",
    "            print(f\"Processed chunk {chunk_idx + 1}/{total_chunks}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {chunk_idx}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = \"/home/ahmed/Task-Aware-audio-coding-perceptual/Data/dataset/S02_P05.wav\"\n",
    "    process_audio_file(input_file, chunk_duration=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(base_path):\n",
    "    \"\"\"Create output directory for spectrograms if it doesn't exist.\"\"\"\n",
    "    output_dir = os.path.join(base_path, 'spectrograms_S02_P05')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def load_audio_chunk(file_path, start_time, chunk_duration):\n",
    "    \"\"\"Load a chunk of audio from the file.\"\"\"\n",
    "    y, sr = librosa.load(file_path, offset=start_time, duration=chunk_duration)\n",
    "    return y, sr\n",
    "\n",
    "def create_spectrogram(y, sr, output_path):\n",
    "    \"\"\"Create and save a spectrogram for the given audio chunk.\"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Create spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    librosa.display.specshow(D, y_axis='log', x_axis='time', sr=sr)\n",
    "    \n",
    "    # Add colorbar and labels\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and close\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def process_audio_file(input_file, max_duration=3600, chunk_duration=3):\n",
    "    \"\"\"\n",
    "    Process a long audio file into spectrograms.\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): Path to input WAV file\n",
    "    max_duration (int): Maximum duration to process in seconds (default: 3600 = 1 hour)\n",
    "    chunk_duration (int): Duration of each chunk in seconds (default: 3)\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    base_path = os.path.dirname(input_file)\n",
    "    output_dir = create_output_directory(base_path)\n",
    "    \n",
    "    # Get total duration of the audio file or use max_duration\n",
    "    total_duration = min(librosa.get_duration(path=input_file), max_duration)\n",
    "    total_chunks = int(np.ceil(total_duration / chunk_duration))\n",
    "    \n",
    "    print(f\"Processing duration: {total_duration:.2f} seconds\")\n",
    "    print(f\"Number of chunks: {total_chunks}\")\n",
    "    \n",
    "    # Process each chunk\n",
    "    for chunk_idx in range(total_chunks):\n",
    "        start_time = chunk_idx * chunk_duration\n",
    "        \n",
    "        # Stop if we've reached the max duration\n",
    "        if start_time >= total_duration:\n",
    "            break\n",
    "        \n",
    "        # Load audio chunk\n",
    "        try:\n",
    "            y, sr = load_audio_chunk(input_file, start_time, chunk_duration)\n",
    "            \n",
    "            # Generate output filename\n",
    "            output_path = os.path.join(\n",
    "                output_dir, \n",
    "                f'spectrogram_chunk_{chunk_idx:04d}.png'\n",
    "            )\n",
    "            \n",
    "            # Create and save spectrogram\n",
    "            create_spectrogram(y, sr, output_path)\n",
    "            \n",
    "            print(f\"Processed chunk {chunk_idx + 1}/{total_chunks}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {chunk_idx}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = \"/home/ahmed/Task-Aware-audio-coding-perceptual/Data/dataset/S02_P05.wav\"\n",
    "    process_audio_file(input_file, max_duration=3600, chunk_duration=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing duration: 3600.00 seconds\n",
      "Number of chunks: 1200\n",
      "Using device: cuda\n",
      "Processed chunk 1/1200\n",
      "Processed chunk 2/1200\n",
      "Processed chunk 3/1200\n",
      "Processed chunk 4/1200\n",
      "Processed chunk 5/1200\n",
      "Processed chunk 6/1200\n",
      "Processed chunk 7/1200\n",
      "Processed chunk 8/1200\n",
      "Processed chunk 9/1200\n",
      "Processed chunk 10/1200\n",
      "Processed chunk 11/1200\n",
      "Processed chunk 12/1200\n",
      "Processed chunk 13/1200\n",
      "Processed chunk 14/1200\n",
      "Processed chunk 15/1200\n",
      "Processed chunk 16/1200\n",
      "Processed chunk 17/1200\n",
      "Processed chunk 18/1200\n",
      "Processed chunk 19/1200\n",
      "Processed chunk 20/1200\n",
      "Processed chunk 21/1200\n",
      "Processed chunk 22/1200\n",
      "Processed chunk 23/1200\n",
      "Processed chunk 24/1200\n",
      "Processed chunk 25/1200\n",
      "Processed chunk 26/1200\n",
      "Processed chunk 27/1200\n",
      "Processed chunk 28/1200\n",
      "Processed chunk 29/1200\n",
      "Processed chunk 30/1200\n",
      "Processed chunk 31/1200\n",
      "Processed chunk 32/1200\n",
      "Processed chunk 33/1200\n",
      "Processed chunk 34/1200\n",
      "Processed chunk 35/1200\n",
      "Processed chunk 36/1200\n",
      "Processed chunk 37/1200\n",
      "Processed chunk 38/1200\n",
      "Processed chunk 39/1200\n",
      "Processed chunk 40/1200\n",
      "Processed chunk 41/1200\n",
      "Processed chunk 42/1200\n",
      "Processed chunk 43/1200\n",
      "Processed chunk 44/1200\n",
      "Processed chunk 45/1200\n",
      "Processed chunk 46/1200\n",
      "Processed chunk 47/1200\n",
      "Processed chunk 48/1200\n",
      "Processed chunk 49/1200\n",
      "Processed chunk 50/1200\n",
      "Processed chunk 51/1200\n",
      "Processed chunk 52/1200\n",
      "Processed chunk 53/1200\n",
      "Processed chunk 54/1200\n",
      "Processed chunk 55/1200\n",
      "Processed chunk 56/1200\n",
      "Processed chunk 57/1200\n",
      "Processed chunk 58/1200\n",
      "Processed chunk 59/1200\n",
      "Processed chunk 60/1200\n",
      "Processed chunk 61/1200\n",
      "Processed chunk 62/1200\n",
      "Processed chunk 63/1200\n",
      "Processed chunk 64/1200\n",
      "Processed chunk 65/1200\n",
      "Processed chunk 66/1200\n",
      "Processed chunk 67/1200\n",
      "Processed chunk 68/1200\n",
      "Processed chunk 69/1200\n",
      "Processed chunk 70/1200\n",
      "Processed chunk 71/1200\n",
      "Processed chunk 72/1200\n",
      "Processed chunk 73/1200\n",
      "Processed chunk 74/1200\n",
      "Processed chunk 75/1200\n",
      "Processed chunk 76/1200\n",
      "Processed chunk 77/1200\n",
      "Processed chunk 78/1200\n",
      "Processed chunk 79/1200\n",
      "Processed chunk 80/1200\n",
      "Processed chunk 81/1200\n",
      "Processed chunk 82/1200\n",
      "Processed chunk 83/1200\n",
      "Processed chunk 84/1200\n",
      "Processed chunk 85/1200\n",
      "Processed chunk 86/1200\n",
      "Processed chunk 87/1200\n",
      "Processed chunk 88/1200\n",
      "Processed chunk 89/1200\n",
      "Processed chunk 90/1200\n",
      "Processed chunk 91/1200\n",
      "Processed chunk 92/1200\n",
      "Processed chunk 93/1200\n",
      "Processed chunk 94/1200\n",
      "Processed chunk 95/1200\n",
      "Processed chunk 96/1200\n",
      "Processed chunk 97/1200\n",
      "Processed chunk 98/1200\n",
      "Processed chunk 99/1200\n",
      "Processed chunk 100/1200\n",
      "Processed chunk 101/1200\n",
      "Processed chunk 102/1200\n",
      "Processed chunk 103/1200\n",
      "Processed chunk 104/1200\n",
      "Processed chunk 105/1200\n",
      "Processed chunk 106/1200\n",
      "Processed chunk 107/1200\n",
      "Processed chunk 108/1200\n",
      "Processed chunk 109/1200\n",
      "Processed chunk 110/1200\n",
      "Processed chunk 111/1200\n",
      "Processed chunk 112/1200\n",
      "Processed chunk 113/1200\n",
      "Processed chunk 114/1200\n",
      "Processed chunk 115/1200\n",
      "Processed chunk 116/1200\n",
      "Processed chunk 117/1200\n",
      "Processed chunk 118/1200\n",
      "Processed chunk 119/1200\n",
      "Processed chunk 120/1200\n",
      "Processed chunk 121/1200\n",
      "Processed chunk 122/1200\n",
      "Processed chunk 123/1200\n",
      "Processed chunk 124/1200\n",
      "Processed chunk 125/1200\n",
      "Processed chunk 126/1200\n",
      "Processed chunk 127/1200\n",
      "Processed chunk 128/1200\n",
      "Processed chunk 129/1200\n",
      "Processed chunk 130/1200\n",
      "Processed chunk 131/1200\n",
      "Processed chunk 132/1200\n",
      "Processed chunk 133/1200\n",
      "Processed chunk 134/1200\n",
      "Processed chunk 135/1200\n",
      "Processed chunk 136/1200\n",
      "Processed chunk 137/1200\n",
      "Processed chunk 138/1200\n",
      "Processed chunk 139/1200\n",
      "Processed chunk 140/1200\n",
      "Processed chunk 141/1200\n",
      "Processed chunk 142/1200\n",
      "Processed chunk 143/1200\n",
      "Processed chunk 144/1200\n",
      "Processed chunk 145/1200\n",
      "Processed chunk 146/1200\n",
      "Processed chunk 147/1200\n",
      "Processed chunk 148/1200\n",
      "Processed chunk 149/1200\n",
      "Processed chunk 150/1200\n",
      "Processed chunk 151/1200\n",
      "Processed chunk 152/1200\n",
      "Processed chunk 153/1200\n",
      "Processed chunk 154/1200\n",
      "Processed chunk 155/1200\n",
      "Processed chunk 156/1200\n",
      "Processed chunk 157/1200\n",
      "Processed chunk 158/1200\n",
      "Processed chunk 159/1200\n",
      "Processed chunk 160/1200\n",
      "Processed chunk 161/1200\n",
      "Processed chunk 162/1200\n",
      "Processed chunk 163/1200\n",
      "Processed chunk 164/1200\n",
      "Processed chunk 165/1200\n",
      "Processed chunk 166/1200\n",
      "Processed chunk 167/1200\n",
      "Processed chunk 168/1200\n",
      "Processed chunk 169/1200\n",
      "Processed chunk 170/1200\n",
      "Processed chunk 171/1200\n",
      "Processed chunk 172/1200\n",
      "Processed chunk 173/1200\n",
      "Processed chunk 174/1200\n",
      "Processed chunk 175/1200\n",
      "Processed chunk 176/1200\n",
      "Processed chunk 177/1200\n",
      "Processed chunk 178/1200\n",
      "Processed chunk 179/1200\n",
      "Processed chunk 180/1200\n",
      "Processed chunk 181/1200\n",
      "Processed chunk 182/1200\n",
      "Processed chunk 183/1200\n",
      "Processed chunk 184/1200\n",
      "Processed chunk 185/1200\n",
      "Processed chunk 186/1200\n",
      "Processed chunk 187/1200\n",
      "Processed chunk 188/1200\n",
      "Processed chunk 189/1200\n",
      "Processed chunk 190/1200\n",
      "Processed chunk 191/1200\n",
      "Processed chunk 192/1200\n",
      "Processed chunk 193/1200\n",
      "Processed chunk 194/1200\n",
      "Processed chunk 195/1200\n",
      "Processed chunk 196/1200\n",
      "Processed chunk 197/1200\n",
      "Processed chunk 198/1200\n",
      "Processed chunk 199/1200\n",
      "Processed chunk 200/1200\n",
      "Processed chunk 201/1200\n",
      "Processed chunk 202/1200\n",
      "Processed chunk 203/1200\n",
      "Processed chunk 204/1200\n",
      "Processed chunk 205/1200\n",
      "Processed chunk 206/1200\n",
      "Processed chunk 207/1200\n",
      "Processed chunk 208/1200\n",
      "Processed chunk 209/1200\n",
      "Processed chunk 210/1200\n",
      "Processed chunk 211/1200\n",
      "Processed chunk 212/1200\n",
      "Processed chunk 213/1200\n",
      "Processed chunk 214/1200\n",
      "Processed chunk 215/1200\n",
      "Processed chunk 216/1200\n",
      "Processed chunk 217/1200\n",
      "Processed chunk 218/1200\n",
      "Processed chunk 219/1200\n",
      "Processed chunk 220/1200\n",
      "Processed chunk 221/1200\n",
      "Processed chunk 222/1200\n",
      "Processed chunk 223/1200\n",
      "Processed chunk 224/1200\n",
      "Processed chunk 225/1200\n",
      "Processed chunk 226/1200\n",
      "Processed chunk 227/1200\n",
      "Processed chunk 228/1200\n",
      "Processed chunk 229/1200\n",
      "Processed chunk 230/1200\n",
      "Processed chunk 231/1200\n",
      "Processed chunk 232/1200\n",
      "Processed chunk 233/1200\n",
      "Processed chunk 234/1200\n",
      "Processed chunk 235/1200\n",
      "Processed chunk 236/1200\n",
      "Processed chunk 237/1200\n",
      "Processed chunk 238/1200\n",
      "Processed chunk 239/1200\n",
      "Processed chunk 240/1200\n",
      "Processed chunk 241/1200\n",
      "Processed chunk 242/1200\n",
      "Processed chunk 243/1200\n",
      "Processed chunk 244/1200\n",
      "Processed chunk 245/1200\n",
      "Processed chunk 246/1200\n",
      "Processed chunk 247/1200\n",
      "Processed chunk 248/1200\n",
      "Processed chunk 249/1200\n",
      "Processed chunk 250/1200\n",
      "Processed chunk 251/1200\n",
      "Processed chunk 252/1200\n",
      "Processed chunk 253/1200\n",
      "Processed chunk 254/1200\n",
      "Processed chunk 255/1200\n",
      "Processed chunk 256/1200\n",
      "Processed chunk 257/1200\n",
      "Processed chunk 258/1200\n",
      "Processed chunk 259/1200\n",
      "Processed chunk 260/1200\n",
      "Processed chunk 261/1200\n",
      "Processed chunk 262/1200\n",
      "Processed chunk 263/1200\n",
      "Processed chunk 264/1200\n",
      "Processed chunk 265/1200\n",
      "Processed chunk 266/1200\n",
      "Processed chunk 267/1200\n",
      "Processed chunk 268/1200\n",
      "Processed chunk 269/1200\n",
      "Processed chunk 270/1200\n",
      "Processed chunk 271/1200\n",
      "Processed chunk 272/1200\n",
      "Processed chunk 273/1200\n",
      "Processed chunk 274/1200\n",
      "Processed chunk 275/1200\n",
      "Processed chunk 276/1200\n",
      "Processed chunk 277/1200\n",
      "Processed chunk 278/1200\n",
      "Processed chunk 279/1200\n",
      "Processed chunk 280/1200\n",
      "Processed chunk 281/1200\n",
      "Processed chunk 282/1200\n",
      "Processed chunk 283/1200\n",
      "Processed chunk 284/1200\n",
      "Processed chunk 285/1200\n",
      "Processed chunk 286/1200\n",
      "Processed chunk 287/1200\n",
      "Processed chunk 288/1200\n",
      "Processed chunk 289/1200\n",
      "Processed chunk 290/1200\n",
      "Processed chunk 291/1200\n",
      "Processed chunk 292/1200\n",
      "Processed chunk 293/1200\n",
      "Processed chunk 294/1200\n",
      "Processed chunk 295/1200\n",
      "Processed chunk 296/1200\n",
      "Processed chunk 297/1200\n",
      "Processed chunk 298/1200\n",
      "Processed chunk 299/1200\n",
      "Processed chunk 300/1200\n",
      "Processed chunk 301/1200\n",
      "Processed chunk 302/1200\n",
      "Processed chunk 303/1200\n",
      "Processed chunk 304/1200\n",
      "Processed chunk 305/1200\n",
      "Processed chunk 306/1200\n",
      "Processed chunk 307/1200\n",
      "Processed chunk 308/1200\n",
      "Processed chunk 309/1200\n",
      "Processed chunk 310/1200\n",
      "Processed chunk 311/1200\n",
      "Processed chunk 312/1200\n",
      "Processed chunk 313/1200\n",
      "Processed chunk 314/1200\n",
      "Processed chunk 315/1200\n",
      "Processed chunk 316/1200\n",
      "Processed chunk 317/1200\n",
      "Processed chunk 318/1200\n",
      "Processed chunk 319/1200\n",
      "Processed chunk 320/1200\n",
      "Processed chunk 321/1200\n",
      "Processed chunk 322/1200\n",
      "Processed chunk 323/1200\n",
      "Processed chunk 324/1200\n",
      "Processed chunk 325/1200\n",
      "Processed chunk 326/1200\n",
      "Processed chunk 327/1200\n",
      "Processed chunk 328/1200\n",
      "Processed chunk 329/1200\n",
      "Processed chunk 330/1200\n",
      "Processed chunk 331/1200\n",
      "Processed chunk 332/1200\n",
      "Processed chunk 333/1200\n",
      "Processed chunk 334/1200\n",
      "Processed chunk 335/1200\n",
      "Processed chunk 336/1200\n",
      "Processed chunk 337/1200\n",
      "Processed chunk 338/1200\n",
      "Processed chunk 339/1200\n",
      "Processed chunk 340/1200\n",
      "Processed chunk 341/1200\n",
      "Processed chunk 342/1200\n",
      "Processed chunk 343/1200\n",
      "Processed chunk 344/1200\n",
      "Processed chunk 345/1200\n",
      "Processed chunk 346/1200\n",
      "Processed chunk 347/1200\n",
      "Processed chunk 348/1200\n",
      "Processed chunk 349/1200\n",
      "Processed chunk 350/1200\n",
      "Processed chunk 351/1200\n",
      "Processed chunk 352/1200\n",
      "Processed chunk 353/1200\n",
      "Processed chunk 354/1200\n",
      "Processed chunk 355/1200\n",
      "Processed chunk 356/1200\n",
      "Processed chunk 357/1200\n",
      "Processed chunk 358/1200\n",
      "Processed chunk 359/1200\n",
      "Processed chunk 360/1200\n",
      "Processed chunk 361/1200\n",
      "Processed chunk 362/1200\n",
      "Processed chunk 363/1200\n",
      "Processed chunk 364/1200\n",
      "Processed chunk 365/1200\n",
      "Processed chunk 366/1200\n",
      "Processed chunk 367/1200\n",
      "Processed chunk 368/1200\n",
      "Processed chunk 369/1200\n",
      "Processed chunk 370/1200\n",
      "Processed chunk 371/1200\n",
      "Processed chunk 372/1200\n",
      "Processed chunk 373/1200\n",
      "Processed chunk 374/1200\n",
      "Processed chunk 375/1200\n",
      "Processed chunk 376/1200\n",
      "Processed chunk 377/1200\n",
      "Processed chunk 378/1200\n",
      "Processed chunk 379/1200\n",
      "Processed chunk 380/1200\n",
      "Processed chunk 381/1200\n",
      "Processed chunk 382/1200\n",
      "Processed chunk 383/1200\n",
      "Processed chunk 384/1200\n",
      "Processed chunk 385/1200\n",
      "Processed chunk 386/1200\n",
      "Processed chunk 387/1200\n",
      "Processed chunk 388/1200\n",
      "Processed chunk 389/1200\n",
      "Processed chunk 390/1200\n",
      "Processed chunk 391/1200\n",
      "Processed chunk 392/1200\n",
      "Processed chunk 393/1200\n",
      "Processed chunk 394/1200\n",
      "Processed chunk 395/1200\n",
      "Processed chunk 396/1200\n",
      "Processed chunk 397/1200\n",
      "Processed chunk 398/1200\n",
      "Processed chunk 399/1200\n",
      "Processed chunk 400/1200\n",
      "Processed chunk 401/1200\n",
      "Processed chunk 402/1200\n",
      "Processed chunk 403/1200\n",
      "Processed chunk 404/1200\n",
      "Processed chunk 405/1200\n",
      "Processed chunk 406/1200\n",
      "Processed chunk 407/1200\n",
      "Processed chunk 408/1200\n",
      "Processed chunk 409/1200\n",
      "Processed chunk 410/1200\n",
      "Processed chunk 411/1200\n",
      "Processed chunk 412/1200\n",
      "Processed chunk 413/1200\n",
      "Processed chunk 414/1200\n",
      "Processed chunk 415/1200\n",
      "Processed chunk 416/1200\n",
      "Processed chunk 417/1200\n",
      "Processed chunk 418/1200\n",
      "Processed chunk 419/1200\n",
      "Processed chunk 420/1200\n",
      "Processed chunk 421/1200\n",
      "Processed chunk 422/1200\n",
      "Processed chunk 423/1200\n",
      "Processed chunk 424/1200\n",
      "Processed chunk 425/1200\n",
      "Processed chunk 426/1200\n",
      "Processed chunk 427/1200\n",
      "Processed chunk 428/1200\n",
      "Processed chunk 429/1200\n",
      "Processed chunk 430/1200\n",
      "Processed chunk 431/1200\n",
      "Processed chunk 432/1200\n",
      "Processed chunk 433/1200\n",
      "Processed chunk 434/1200\n",
      "Processed chunk 435/1200\n",
      "Processed chunk 436/1200\n",
      "Processed chunk 437/1200\n",
      "Processed chunk 438/1200\n",
      "Processed chunk 439/1200\n",
      "Processed chunk 440/1200\n",
      "Processed chunk 441/1200\n",
      "Processed chunk 442/1200\n",
      "Processed chunk 443/1200\n",
      "Processed chunk 444/1200\n",
      "Processed chunk 445/1200\n",
      "Processed chunk 446/1200\n",
      "Processed chunk 447/1200\n",
      "Processed chunk 448/1200\n",
      "Processed chunk 449/1200\n",
      "Processed chunk 450/1200\n",
      "Processed chunk 451/1200\n",
      "Processed chunk 452/1200\n",
      "Processed chunk 453/1200\n",
      "Processed chunk 454/1200\n",
      "Processed chunk 455/1200\n",
      "Processed chunk 456/1200\n",
      "Processed chunk 457/1200\n",
      "Processed chunk 458/1200\n",
      "Processed chunk 459/1200\n",
      "Processed chunk 460/1200\n",
      "Processed chunk 461/1200\n",
      "Processed chunk 462/1200\n",
      "Processed chunk 463/1200\n",
      "Processed chunk 464/1200\n",
      "Processed chunk 465/1200\n",
      "Processed chunk 466/1200\n",
      "Processed chunk 467/1200\n",
      "Processed chunk 468/1200\n",
      "Processed chunk 469/1200\n",
      "Processed chunk 470/1200\n",
      "Processed chunk 471/1200\n",
      "Processed chunk 472/1200\n",
      "Processed chunk 473/1200\n",
      "Processed chunk 474/1200\n",
      "Processed chunk 475/1200\n",
      "Processed chunk 476/1200\n",
      "Processed chunk 477/1200\n",
      "Processed chunk 478/1200\n",
      "Processed chunk 479/1200\n",
      "Processed chunk 480/1200\n",
      "Processed chunk 481/1200\n",
      "Processed chunk 482/1200\n",
      "Processed chunk 483/1200\n",
      "Processed chunk 484/1200\n",
      "Processed chunk 485/1200\n",
      "Processed chunk 486/1200\n",
      "Processed chunk 487/1200\n",
      "Processed chunk 488/1200\n",
      "Processed chunk 489/1200\n",
      "Processed chunk 490/1200\n",
      "Processed chunk 491/1200\n",
      "Processed chunk 492/1200\n",
      "Processed chunk 493/1200\n",
      "Processed chunk 494/1200\n",
      "Processed chunk 495/1200\n",
      "Processed chunk 496/1200\n",
      "Processed chunk 497/1200\n",
      "Processed chunk 498/1200\n",
      "Processed chunk 499/1200\n",
      "Processed chunk 500/1200\n",
      "Processed chunk 501/1200\n",
      "Processed chunk 502/1200\n",
      "Processed chunk 503/1200\n",
      "Processed chunk 504/1200\n",
      "Processed chunk 505/1200\n",
      "Processed chunk 506/1200\n",
      "Processed chunk 507/1200\n",
      "Processed chunk 508/1200\n",
      "Processed chunk 509/1200\n",
      "Processed chunk 510/1200\n",
      "Processed chunk 511/1200\n",
      "Processed chunk 512/1200\n",
      "Processed chunk 513/1200\n",
      "Processed chunk 514/1200\n",
      "Processed chunk 515/1200\n",
      "Processed chunk 516/1200\n",
      "Processed chunk 517/1200\n",
      "Processed chunk 518/1200\n",
      "Processed chunk 519/1200\n",
      "Processed chunk 520/1200\n",
      "Processed chunk 521/1200\n",
      "Processed chunk 522/1200\n",
      "Processed chunk 523/1200\n",
      "Processed chunk 524/1200\n",
      "Processed chunk 525/1200\n",
      "Processed chunk 526/1200\n",
      "Processed chunk 527/1200\n",
      "Processed chunk 528/1200\n",
      "Processed chunk 529/1200\n",
      "Processed chunk 530/1200\n",
      "Processed chunk 531/1200\n",
      "Processed chunk 532/1200\n",
      "Processed chunk 533/1200\n",
      "Processed chunk 534/1200\n",
      "Processed chunk 535/1200\n",
      "Processed chunk 536/1200\n",
      "Processed chunk 537/1200\n",
      "Processed chunk 538/1200\n",
      "Processed chunk 539/1200\n",
      "Processed chunk 540/1200\n",
      "Processed chunk 541/1200\n",
      "Processed chunk 542/1200\n",
      "Processed chunk 543/1200\n",
      "Processed chunk 544/1200\n",
      "Processed chunk 545/1200\n",
      "Processed chunk 546/1200\n",
      "Processed chunk 547/1200\n",
      "Processed chunk 548/1200\n",
      "Processed chunk 549/1200\n",
      "Processed chunk 550/1200\n",
      "Processed chunk 551/1200\n",
      "Processed chunk 552/1200\n",
      "Processed chunk 553/1200\n",
      "Processed chunk 554/1200\n",
      "Processed chunk 555/1200\n",
      "Processed chunk 556/1200\n",
      "Processed chunk 557/1200\n",
      "Processed chunk 558/1200\n",
      "Processed chunk 559/1200\n",
      "Processed chunk 560/1200\n",
      "Processed chunk 561/1200\n",
      "Processed chunk 562/1200\n",
      "Processed chunk 563/1200\n",
      "Processed chunk 564/1200\n",
      "Processed chunk 565/1200\n",
      "Processed chunk 566/1200\n",
      "Processed chunk 567/1200\n",
      "Processed chunk 568/1200\n",
      "Processed chunk 569/1200\n",
      "Processed chunk 570/1200\n",
      "Processed chunk 571/1200\n",
      "Processed chunk 572/1200\n",
      "Processed chunk 573/1200\n",
      "Processed chunk 574/1200\n",
      "Processed chunk 575/1200\n",
      "Processed chunk 576/1200\n",
      "Processed chunk 577/1200\n",
      "Processed chunk 578/1200\n",
      "Processed chunk 579/1200\n",
      "Processed chunk 580/1200\n",
      "Processed chunk 581/1200\n",
      "Processed chunk 582/1200\n",
      "Processed chunk 583/1200\n",
      "Processed chunk 584/1200\n",
      "Processed chunk 585/1200\n",
      "Processed chunk 586/1200\n",
      "Processed chunk 587/1200\n",
      "Processed chunk 588/1200\n",
      "Processed chunk 589/1200\n",
      "Processed chunk 590/1200\n",
      "Processed chunk 591/1200\n",
      "Processed chunk 592/1200\n",
      "Processed chunk 593/1200\n",
      "Processed chunk 594/1200\n",
      "Processed chunk 595/1200\n",
      "Processed chunk 596/1200\n",
      "Processed chunk 597/1200\n",
      "Processed chunk 598/1200\n",
      "Processed chunk 599/1200\n",
      "Processed chunk 600/1200\n",
      "Processed chunk 601/1200\n",
      "Processed chunk 602/1200\n",
      "Processed chunk 603/1200\n",
      "Processed chunk 604/1200\n",
      "Processed chunk 605/1200\n",
      "Processed chunk 606/1200\n",
      "Processed chunk 607/1200\n",
      "Processed chunk 608/1200\n",
      "Processed chunk 609/1200\n",
      "Processed chunk 610/1200\n",
      "Processed chunk 611/1200\n",
      "Processed chunk 612/1200\n",
      "Processed chunk 613/1200\n",
      "Processed chunk 614/1200\n",
      "Processed chunk 615/1200\n",
      "Processed chunk 616/1200\n",
      "Processed chunk 617/1200\n",
      "Processed chunk 618/1200\n",
      "Processed chunk 619/1200\n",
      "Processed chunk 620/1200\n",
      "Processed chunk 621/1200\n",
      "Processed chunk 622/1200\n",
      "Processed chunk 623/1200\n",
      "Processed chunk 624/1200\n",
      "Processed chunk 625/1200\n",
      "Processed chunk 626/1200\n",
      "Processed chunk 627/1200\n",
      "Processed chunk 628/1200\n",
      "Processed chunk 629/1200\n",
      "Processed chunk 630/1200\n",
      "Processed chunk 631/1200\n",
      "Processed chunk 632/1200\n",
      "Processed chunk 633/1200\n",
      "Processed chunk 634/1200\n",
      "Processed chunk 635/1200\n",
      "Processed chunk 636/1200\n",
      "Processed chunk 637/1200\n",
      "Processed chunk 638/1200\n",
      "Processed chunk 639/1200\n",
      "Processed chunk 640/1200\n",
      "Processed chunk 641/1200\n",
      "Processed chunk 642/1200\n",
      "Processed chunk 643/1200\n",
      "Processed chunk 644/1200\n",
      "Processed chunk 645/1200\n",
      "Processed chunk 646/1200\n",
      "Processed chunk 647/1200\n",
      "Processed chunk 648/1200\n",
      "Processed chunk 649/1200\n",
      "Processed chunk 650/1200\n",
      "Processed chunk 651/1200\n",
      "Processed chunk 652/1200\n",
      "Processed chunk 653/1200\n",
      "Processed chunk 654/1200\n",
      "Processed chunk 655/1200\n",
      "Processed chunk 656/1200\n",
      "Processed chunk 657/1200\n",
      "Processed chunk 658/1200\n",
      "Processed chunk 659/1200\n",
      "Processed chunk 660/1200\n",
      "Processed chunk 661/1200\n",
      "Processed chunk 662/1200\n",
      "Processed chunk 663/1200\n",
      "Processed chunk 664/1200\n",
      "Processed chunk 665/1200\n",
      "Processed chunk 666/1200\n",
      "Processed chunk 667/1200\n",
      "Processed chunk 668/1200\n",
      "Processed chunk 669/1200\n",
      "Processed chunk 670/1200\n",
      "Processed chunk 671/1200\n",
      "Processed chunk 672/1200\n",
      "Processed chunk 673/1200\n",
      "Processed chunk 674/1200\n",
      "Processed chunk 675/1200\n",
      "Processed chunk 676/1200\n",
      "Processed chunk 677/1200\n",
      "Processed chunk 678/1200\n",
      "Processed chunk 679/1200\n",
      "Processed chunk 680/1200\n",
      "Processed chunk 681/1200\n",
      "Processed chunk 682/1200\n",
      "Processed chunk 683/1200\n",
      "Processed chunk 684/1200\n",
      "Processed chunk 685/1200\n",
      "Processed chunk 686/1200\n",
      "Processed chunk 687/1200\n",
      "Processed chunk 688/1200\n",
      "Processed chunk 689/1200\n",
      "Processed chunk 690/1200\n",
      "Processed chunk 691/1200\n",
      "Processed chunk 692/1200\n",
      "Processed chunk 693/1200\n",
      "Processed chunk 694/1200\n",
      "Processed chunk 695/1200\n",
      "Processed chunk 696/1200\n",
      "Processed chunk 697/1200\n",
      "Processed chunk 698/1200\n",
      "Processed chunk 699/1200\n",
      "Processed chunk 700/1200\n",
      "Processed chunk 701/1200\n",
      "Processed chunk 702/1200\n",
      "Processed chunk 703/1200\n",
      "Processed chunk 704/1200\n",
      "Processed chunk 705/1200\n",
      "Processed chunk 706/1200\n",
      "Processed chunk 707/1200\n",
      "Processed chunk 708/1200\n",
      "Processed chunk 709/1200\n",
      "Processed chunk 710/1200\n",
      "Processed chunk 711/1200\n",
      "Processed chunk 712/1200\n",
      "Processed chunk 713/1200\n",
      "Processed chunk 714/1200\n",
      "Processed chunk 715/1200\n",
      "Processed chunk 716/1200\n",
      "Processed chunk 717/1200\n",
      "Processed chunk 718/1200\n",
      "Processed chunk 719/1200\n",
      "Processed chunk 720/1200\n",
      "Processed chunk 721/1200\n",
      "Processed chunk 722/1200\n",
      "Processed chunk 723/1200\n",
      "Processed chunk 724/1200\n",
      "Processed chunk 725/1200\n",
      "Processed chunk 726/1200\n",
      "Processed chunk 727/1200\n",
      "Processed chunk 728/1200\n",
      "Processed chunk 729/1200\n",
      "Processed chunk 730/1200\n",
      "Processed chunk 731/1200\n",
      "Processed chunk 732/1200\n",
      "Processed chunk 733/1200\n",
      "Processed chunk 734/1200\n",
      "Processed chunk 735/1200\n",
      "Processed chunk 736/1200\n",
      "Processed chunk 737/1200\n",
      "Processed chunk 738/1200\n",
      "Processed chunk 739/1200\n",
      "Processed chunk 740/1200\n",
      "Processed chunk 741/1200\n",
      "Processed chunk 742/1200\n",
      "Processed chunk 743/1200\n",
      "Processed chunk 744/1200\n",
      "Processed chunk 745/1200\n",
      "Processed chunk 746/1200\n",
      "Processed chunk 747/1200\n",
      "Processed chunk 748/1200\n",
      "Processed chunk 749/1200\n",
      "Processed chunk 750/1200\n",
      "Processed chunk 751/1200\n",
      "Processed chunk 752/1200\n",
      "Processed chunk 753/1200\n",
      "Processed chunk 754/1200\n",
      "Processed chunk 755/1200\n",
      "Processed chunk 756/1200\n",
      "Processed chunk 757/1200\n",
      "Processed chunk 758/1200\n",
      "Processed chunk 759/1200\n",
      "Processed chunk 760/1200\n",
      "Processed chunk 761/1200\n",
      "Processed chunk 762/1200\n",
      "Processed chunk 763/1200\n",
      "Processed chunk 764/1200\n",
      "Processed chunk 765/1200\n",
      "Processed chunk 766/1200\n",
      "Processed chunk 767/1200\n",
      "Processed chunk 768/1200\n",
      "Processed chunk 769/1200\n",
      "Processed chunk 770/1200\n",
      "Processed chunk 771/1200\n",
      "Processed chunk 772/1200\n",
      "Processed chunk 773/1200\n",
      "Processed chunk 774/1200\n",
      "Processed chunk 775/1200\n",
      "Processed chunk 776/1200\n",
      "Processed chunk 777/1200\n",
      "Processed chunk 778/1200\n",
      "Processed chunk 779/1200\n",
      "Processed chunk 780/1200\n",
      "Processed chunk 781/1200\n",
      "Processed chunk 782/1200\n",
      "Processed chunk 783/1200\n",
      "Processed chunk 784/1200\n",
      "Processed chunk 785/1200\n",
      "Processed chunk 786/1200\n",
      "Processed chunk 787/1200\n",
      "Processed chunk 788/1200\n",
      "Processed chunk 789/1200\n",
      "Processed chunk 790/1200\n",
      "Processed chunk 791/1200\n",
      "Processed chunk 792/1200\n",
      "Processed chunk 793/1200\n",
      "Processed chunk 794/1200\n",
      "Processed chunk 795/1200\n",
      "Processed chunk 796/1200\n",
      "Processed chunk 797/1200\n",
      "Processed chunk 798/1200\n",
      "Processed chunk 799/1200\n",
      "Processed chunk 800/1200\n",
      "Processed chunk 801/1200\n",
      "Processed chunk 802/1200\n",
      "Processed chunk 803/1200\n",
      "Processed chunk 804/1200\n",
      "Processed chunk 805/1200\n",
      "Processed chunk 806/1200\n",
      "Processed chunk 807/1200\n",
      "Processed chunk 808/1200\n",
      "Processed chunk 809/1200\n",
      "Processed chunk 810/1200\n",
      "Processed chunk 811/1200\n",
      "Processed chunk 812/1200\n",
      "Processed chunk 813/1200\n",
      "Processed chunk 814/1200\n",
      "Processed chunk 815/1200\n",
      "Processed chunk 816/1200\n",
      "Processed chunk 817/1200\n",
      "Processed chunk 818/1200\n",
      "Processed chunk 819/1200\n",
      "Processed chunk 820/1200\n",
      "Processed chunk 821/1200\n",
      "Processed chunk 822/1200\n",
      "Processed chunk 823/1200\n",
      "Processed chunk 824/1200\n",
      "Processed chunk 825/1200\n",
      "Processed chunk 826/1200\n",
      "Processed chunk 827/1200\n",
      "Processed chunk 828/1200\n",
      "Processed chunk 829/1200\n",
      "Processed chunk 830/1200\n",
      "Processed chunk 831/1200\n",
      "Processed chunk 832/1200\n",
      "Processed chunk 833/1200\n",
      "Processed chunk 834/1200\n",
      "Processed chunk 835/1200\n",
      "Processed chunk 836/1200\n",
      "Processed chunk 837/1200\n",
      "Processed chunk 838/1200\n",
      "Processed chunk 839/1200\n",
      "Processed chunk 840/1200\n",
      "Processed chunk 841/1200\n",
      "Processed chunk 842/1200\n",
      "Processed chunk 843/1200\n",
      "Processed chunk 844/1200\n",
      "Processed chunk 845/1200\n",
      "Processed chunk 846/1200\n",
      "Processed chunk 847/1200\n",
      "Processed chunk 848/1200\n",
      "Processed chunk 849/1200\n",
      "Processed chunk 850/1200\n",
      "Processed chunk 851/1200\n",
      "Processed chunk 852/1200\n",
      "Processed chunk 853/1200\n",
      "Processed chunk 854/1200\n",
      "Processed chunk 855/1200\n",
      "Processed chunk 856/1200\n",
      "Processed chunk 857/1200\n",
      "Processed chunk 858/1200\n",
      "Processed chunk 859/1200\n",
      "Processed chunk 860/1200\n",
      "Processed chunk 861/1200\n",
      "Processed chunk 862/1200\n",
      "Processed chunk 863/1200\n",
      "Processed chunk 864/1200\n",
      "Processed chunk 865/1200\n",
      "Processed chunk 866/1200\n",
      "Processed chunk 867/1200\n",
      "Processed chunk 868/1200\n",
      "Processed chunk 869/1200\n",
      "Processed chunk 870/1200\n",
      "Processed chunk 871/1200\n",
      "Processed chunk 872/1200\n",
      "Processed chunk 873/1200\n",
      "Processed chunk 874/1200\n",
      "Processed chunk 875/1200\n",
      "Processed chunk 876/1200\n",
      "Processed chunk 877/1200\n",
      "Processed chunk 878/1200\n",
      "Processed chunk 879/1200\n",
      "Processed chunk 880/1200\n",
      "Processed chunk 881/1200\n",
      "Processed chunk 882/1200\n",
      "Processed chunk 883/1200\n",
      "Processed chunk 884/1200\n",
      "Processed chunk 885/1200\n",
      "Processed chunk 886/1200\n",
      "Processed chunk 887/1200\n",
      "Processed chunk 888/1200\n",
      "Processed chunk 889/1200\n",
      "Processed chunk 890/1200\n",
      "Processed chunk 891/1200\n",
      "Processed chunk 892/1200\n",
      "Processed chunk 893/1200\n",
      "Processed chunk 894/1200\n",
      "Processed chunk 895/1200\n",
      "Processed chunk 896/1200\n",
      "Processed chunk 897/1200\n",
      "Processed chunk 898/1200\n",
      "Processed chunk 899/1200\n",
      "Processed chunk 900/1200\n",
      "Processed chunk 901/1200\n",
      "Processed chunk 902/1200\n",
      "Processed chunk 903/1200\n",
      "Processed chunk 904/1200\n",
      "Processed chunk 905/1200\n",
      "Processed chunk 906/1200\n",
      "Processed chunk 907/1200\n",
      "Processed chunk 908/1200\n",
      "Processed chunk 909/1200\n",
      "Processed chunk 910/1200\n",
      "Processed chunk 911/1200\n",
      "Processed chunk 912/1200\n",
      "Processed chunk 913/1200\n",
      "Processed chunk 914/1200\n",
      "Processed chunk 915/1200\n",
      "Processed chunk 916/1200\n",
      "Processed chunk 917/1200\n",
      "Processed chunk 918/1200\n",
      "Processed chunk 919/1200\n",
      "Processed chunk 920/1200\n",
      "Processed chunk 921/1200\n",
      "Processed chunk 922/1200\n",
      "Processed chunk 923/1200\n",
      "Processed chunk 924/1200\n",
      "Processed chunk 925/1200\n",
      "Processed chunk 926/1200\n",
      "Processed chunk 927/1200\n",
      "Processed chunk 928/1200\n",
      "Processed chunk 929/1200\n",
      "Processed chunk 930/1200\n",
      "Processed chunk 931/1200\n",
      "Processed chunk 932/1200\n",
      "Processed chunk 933/1200\n",
      "Processed chunk 934/1200\n",
      "Processed chunk 935/1200\n",
      "Processed chunk 936/1200\n",
      "Processed chunk 937/1200\n",
      "Processed chunk 938/1200\n",
      "Processed chunk 939/1200\n",
      "Processed chunk 940/1200\n",
      "Processed chunk 941/1200\n",
      "Processed chunk 942/1200\n",
      "Processed chunk 943/1200\n",
      "Processed chunk 944/1200\n",
      "Processed chunk 945/1200\n",
      "Processed chunk 946/1200\n",
      "Processed chunk 947/1200\n",
      "Processed chunk 948/1200\n",
      "Processed chunk 949/1200\n",
      "Processed chunk 950/1200\n",
      "Processed chunk 951/1200\n",
      "Processed chunk 952/1200\n",
      "Processed chunk 953/1200\n",
      "Processed chunk 954/1200\n",
      "Processed chunk 955/1200\n",
      "Processed chunk 956/1200\n",
      "Processed chunk 957/1200\n",
      "Processed chunk 958/1200\n",
      "Processed chunk 959/1200\n",
      "Processed chunk 960/1200\n",
      "Processed chunk 961/1200\n",
      "Processed chunk 962/1200\n",
      "Processed chunk 963/1200\n",
      "Processed chunk 964/1200\n",
      "Processed chunk 965/1200\n",
      "Processed chunk 966/1200\n",
      "Processed chunk 967/1200\n",
      "Processed chunk 968/1200\n",
      "Processed chunk 969/1200\n",
      "Processed chunk 970/1200\n",
      "Processed chunk 971/1200\n",
      "Processed chunk 972/1200\n",
      "Processed chunk 973/1200\n",
      "Processed chunk 974/1200\n",
      "Processed chunk 975/1200\n",
      "Processed chunk 976/1200\n",
      "Processed chunk 977/1200\n",
      "Processed chunk 978/1200\n",
      "Processed chunk 979/1200\n",
      "Processed chunk 980/1200\n",
      "Processed chunk 981/1200\n",
      "Processed chunk 982/1200\n",
      "Processed chunk 983/1200\n",
      "Processed chunk 984/1200\n",
      "Processed chunk 985/1200\n",
      "Processed chunk 986/1200\n",
      "Processed chunk 987/1200\n",
      "Processed chunk 988/1200\n",
      "Processed chunk 989/1200\n",
      "Processed chunk 990/1200\n",
      "Processed chunk 991/1200\n",
      "Processed chunk 992/1200\n",
      "Processed chunk 993/1200\n",
      "Processed chunk 994/1200\n",
      "Processed chunk 995/1200\n",
      "Processed chunk 996/1200\n",
      "Processed chunk 997/1200\n",
      "Processed chunk 998/1200\n",
      "Processed chunk 999/1200\n",
      "Processed chunk 1000/1200\n",
      "Processed chunk 1001/1200\n",
      "Processed chunk 1002/1200\n",
      "Processed chunk 1003/1200\n",
      "Processed chunk 1004/1200\n",
      "Processed chunk 1005/1200\n",
      "Processed chunk 1006/1200\n",
      "Processed chunk 1007/1200\n",
      "Processed chunk 1008/1200\n",
      "Processed chunk 1009/1200\n",
      "Processed chunk 1010/1200\n",
      "Processed chunk 1011/1200\n",
      "Processed chunk 1012/1200\n",
      "Processed chunk 1013/1200\n",
      "Processed chunk 1014/1200\n",
      "Processed chunk 1015/1200\n",
      "Processed chunk 1016/1200\n",
      "Processed chunk 1017/1200\n",
      "Processed chunk 1018/1200\n",
      "Processed chunk 1019/1200\n",
      "Processed chunk 1020/1200\n",
      "Processed chunk 1021/1200\n",
      "Processed chunk 1022/1200\n",
      "Processed chunk 1023/1200\n",
      "Processed chunk 1024/1200\n",
      "Processed chunk 1025/1200\n",
      "Processed chunk 1026/1200\n",
      "Processed chunk 1027/1200\n",
      "Processed chunk 1028/1200\n",
      "Processed chunk 1029/1200\n",
      "Processed chunk 1030/1200\n",
      "Processed chunk 1031/1200\n",
      "Processed chunk 1032/1200\n",
      "Processed chunk 1033/1200\n",
      "Processed chunk 1034/1200\n",
      "Processed chunk 1035/1200\n",
      "Processed chunk 1036/1200\n",
      "Processed chunk 1037/1200\n",
      "Processed chunk 1038/1200\n",
      "Processed chunk 1039/1200\n",
      "Processed chunk 1040/1200\n",
      "Processed chunk 1041/1200\n",
      "Processed chunk 1042/1200\n",
      "Processed chunk 1043/1200\n",
      "Processed chunk 1044/1200\n",
      "Processed chunk 1045/1200\n",
      "Processed chunk 1046/1200\n",
      "Processed chunk 1047/1200\n",
      "Processed chunk 1048/1200\n",
      "Processed chunk 1049/1200\n",
      "Processed chunk 1050/1200\n",
      "Processed chunk 1051/1200\n",
      "Processed chunk 1052/1200\n",
      "Processed chunk 1053/1200\n",
      "Processed chunk 1054/1200\n",
      "Processed chunk 1055/1200\n",
      "Processed chunk 1056/1200\n",
      "Processed chunk 1057/1200\n",
      "Processed chunk 1058/1200\n",
      "Processed chunk 1059/1200\n",
      "Processed chunk 1060/1200\n",
      "Processed chunk 1061/1200\n",
      "Processed chunk 1062/1200\n",
      "Processed chunk 1063/1200\n",
      "Processed chunk 1064/1200\n",
      "Processed chunk 1065/1200\n",
      "Processed chunk 1066/1200\n",
      "Processed chunk 1067/1200\n",
      "Processed chunk 1068/1200\n",
      "Processed chunk 1069/1200\n",
      "Processed chunk 1070/1200\n",
      "Processed chunk 1071/1200\n",
      "Processed chunk 1072/1200\n",
      "Processed chunk 1073/1200\n",
      "Processed chunk 1074/1200\n",
      "Processed chunk 1075/1200\n",
      "Processed chunk 1076/1200\n",
      "Processed chunk 1077/1200\n",
      "Processed chunk 1078/1200\n",
      "Processed chunk 1079/1200\n",
      "Processed chunk 1080/1200\n",
      "Processed chunk 1081/1200\n",
      "Processed chunk 1082/1200\n",
      "Processed chunk 1083/1200\n",
      "Processed chunk 1084/1200\n",
      "Processed chunk 1085/1200\n",
      "Processed chunk 1086/1200\n",
      "Processed chunk 1087/1200\n",
      "Processed chunk 1088/1200\n",
      "Processed chunk 1089/1200\n",
      "Processed chunk 1090/1200\n",
      "Processed chunk 1091/1200\n",
      "Processed chunk 1092/1200\n",
      "Processed chunk 1093/1200\n",
      "Processed chunk 1094/1200\n",
      "Processed chunk 1095/1200\n",
      "Processed chunk 1096/1200\n",
      "Processed chunk 1097/1200\n",
      "Processed chunk 1098/1200\n",
      "Processed chunk 1099/1200\n",
      "Processed chunk 1100/1200\n",
      "Processed chunk 1101/1200\n",
      "Processed chunk 1102/1200\n",
      "Processed chunk 1103/1200\n",
      "Processed chunk 1104/1200\n",
      "Processed chunk 1105/1200\n",
      "Processed chunk 1106/1200\n",
      "Processed chunk 1107/1200\n",
      "Processed chunk 1108/1200\n",
      "Processed chunk 1109/1200\n",
      "Processed chunk 1110/1200\n",
      "Processed chunk 1111/1200\n",
      "Processed chunk 1112/1200\n",
      "Processed chunk 1113/1200\n",
      "Processed chunk 1114/1200\n",
      "Processed chunk 1115/1200\n",
      "Processed chunk 1116/1200\n",
      "Processed chunk 1117/1200\n",
      "Processed chunk 1118/1200\n",
      "Processed chunk 1119/1200\n",
      "Processed chunk 1120/1200\n",
      "Processed chunk 1121/1200\n",
      "Processed chunk 1122/1200\n",
      "Processed chunk 1123/1200\n",
      "Processed chunk 1124/1200\n",
      "Processed chunk 1125/1200\n",
      "Processed chunk 1126/1200\n",
      "Processed chunk 1127/1200\n",
      "Processed chunk 1128/1200\n",
      "Processed chunk 1129/1200\n",
      "Processed chunk 1130/1200\n",
      "Processed chunk 1131/1200\n",
      "Processed chunk 1132/1200\n",
      "Processed chunk 1133/1200\n",
      "Processed chunk 1134/1200\n",
      "Processed chunk 1135/1200\n",
      "Processed chunk 1136/1200\n",
      "Processed chunk 1137/1200\n",
      "Processed chunk 1138/1200\n",
      "Processed chunk 1139/1200\n",
      "Processed chunk 1140/1200\n",
      "Processed chunk 1141/1200\n",
      "Processed chunk 1142/1200\n",
      "Processed chunk 1143/1200\n",
      "Processed chunk 1144/1200\n",
      "Processed chunk 1145/1200\n",
      "Processed chunk 1146/1200\n",
      "Processed chunk 1147/1200\n",
      "Processed chunk 1148/1200\n",
      "Processed chunk 1149/1200\n",
      "Processed chunk 1150/1200\n",
      "Processed chunk 1151/1200\n",
      "Processed chunk 1152/1200\n",
      "Processed chunk 1153/1200\n",
      "Processed chunk 1154/1200\n",
      "Processed chunk 1155/1200\n",
      "Processed chunk 1156/1200\n",
      "Processed chunk 1157/1200\n",
      "Processed chunk 1158/1200\n",
      "Processed chunk 1159/1200\n",
      "Processed chunk 1160/1200\n",
      "Processed chunk 1161/1200\n",
      "Processed chunk 1162/1200\n",
      "Processed chunk 1163/1200\n",
      "Processed chunk 1164/1200\n",
      "Processed chunk 1165/1200\n",
      "Processed chunk 1166/1200\n",
      "Processed chunk 1167/1200\n",
      "Processed chunk 1168/1200\n",
      "Processed chunk 1169/1200\n",
      "Processed chunk 1170/1200\n",
      "Processed chunk 1171/1200\n",
      "Processed chunk 1172/1200\n",
      "Processed chunk 1173/1200\n",
      "Processed chunk 1174/1200\n",
      "Processed chunk 1175/1200\n",
      "Processed chunk 1176/1200\n",
      "Processed chunk 1177/1200\n",
      "Processed chunk 1178/1200\n",
      "Processed chunk 1179/1200\n",
      "Processed chunk 1180/1200\n",
      "Processed chunk 1181/1200\n",
      "Processed chunk 1182/1200\n",
      "Processed chunk 1183/1200\n",
      "Processed chunk 1184/1200\n",
      "Processed chunk 1185/1200\n",
      "Processed chunk 1186/1200\n",
      "Processed chunk 1187/1200\n",
      "Processed chunk 1188/1200\n",
      "Processed chunk 1189/1200\n",
      "Processed chunk 1190/1200\n",
      "Processed chunk 1191/1200\n",
      "Processed chunk 1192/1200\n",
      "Processed chunk 1193/1200\n",
      "Processed chunk 1194/1200\n",
      "Processed chunk 1195/1200\n",
      "Processed chunk 1196/1200\n",
      "Processed chunk 1197/1200\n",
      "Processed chunk 1198/1200\n",
      "Processed chunk 1199/1200\n",
      "Processed chunk 1200/1200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "def create_output_directory(base_path):\n",
    "    \"\"\"Create output directory for spectrograms if it doesn't exist.\"\"\"\n",
    "    output_dir = os.path.join(base_path, 'spectrograms_S02_U03CH1')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def load_audio_chunk(file_path, start_time, chunk_duration, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load a chunk of audio from the file using torchaudio.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the audio file\n",
    "    start_time (float): Start time of the chunk in seconds\n",
    "    chunk_duration (float): Duration of the chunk in seconds\n",
    "    device (str): Device to load the tensor on (cuda or cpu)\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: Audio chunk\n",
    "    int: Sample rate\n",
    "    \"\"\"\n",
    "    # First, get the sample rate\n",
    "    info = torchaudio.info(file_path)\n",
    "    sample_rate = info.sample_rate\n",
    "    \n",
    "    # Calculate frame offsets\n",
    "    frame_offset = int(start_time * sample_rate)\n",
    "    num_frames = int(chunk_duration * sample_rate)\n",
    "    \n",
    "    # Load audio chunk\n",
    "    waveform, loaded_sample_rate = torchaudio.load(\n",
    "        file_path, \n",
    "        frame_offset=frame_offset, \n",
    "        num_frames=num_frames\n",
    "    )\n",
    "    \n",
    "    # Ensure mono channel\n",
    "    if waveform.size(0) > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    # Move to specified device\n",
    "    return waveform.to(device), sample_rate\n",
    "\n",
    "def create_spectrogram(y, sr, output_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Create and save a spectrogram for the given audio chunk.\n",
    "    \n",
    "    Parameters:\n",
    "    y (torch.Tensor): Audio chunk\n",
    "    sr (int): Sample rate\n",
    "    output_path (str): Path to save the spectrogram\n",
    "    device (str): Device to perform computations on\n",
    "    \"\"\"\n",
    "    # Ensure y is on CPU for numpy operations\n",
    "    y_np = y.cpu().numpy().squeeze()\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Use fixed STFT parameters\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    \n",
    "    try:\n",
    "        # Compute spectrogram using librosa\n",
    "        D = librosa.stft(y_np, n_fft=n_fft, hop_length=hop_length)\n",
    "        D_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "        \n",
    "        # Display spectrogram\n",
    "        librosa.display.specshow(D_db, sr=sr, hop_length=hop_length, \n",
    "                                 x_axis='time', y_axis='log')\n",
    "        \n",
    "        # Add colorbar and labels\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Spectrogram')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save and close\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating spectrogram: {e}\")\n",
    "        plt.close()\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def process_audio_file(input_file, max_duration=3600, chunk_duration=3, device='cuda'):\n",
    "    \"\"\"\n",
    "    Process a long audio file into spectrograms using CUDA.\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): Path to input WAV file\n",
    "    max_duration (int): Maximum duration to process in seconds (default: 3600 = 1 hour)\n",
    "    chunk_duration (int): Duration of each chunk in seconds (default: 3)\n",
    "    device (str): Device to use for processing (cuda or cpu)\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    if device == 'cuda' and not torch.cuda.is_available():\n",
    "        print(\"CUDA not available. Falling back to CPU.\")\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # Create output directory\n",
    "    base_path = os.path.dirname(input_file)\n",
    "    output_dir = create_output_directory(base_path)\n",
    "    \n",
    "    # Get total duration of the audio file or use max_duration\n",
    "    total_duration = min(librosa.get_duration(path=input_file), max_duration)\n",
    "    total_chunks = int(np.ceil(total_duration / chunk_duration))\n",
    "    \n",
    "    print(f\"Processing duration: {total_duration:.2f} seconds\")\n",
    "    print(f\"Number of chunks: {total_chunks}\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Process each chunk\n",
    "    for chunk_idx in range(total_chunks):\n",
    "        start_time = chunk_idx * chunk_duration\n",
    "        \n",
    "        # Stop if we've reached the max duration\n",
    "        if start_time >= total_duration:\n",
    "            break\n",
    "        \n",
    "        # Load audio chunk\n",
    "        try:\n",
    "            y, sr = load_audio_chunk(input_file, start_time, chunk_duration, device)\n",
    "            \n",
    "            # Generate output filename\n",
    "            output_path = os.path.join(\n",
    "                output_dir, \n",
    "                f'spectrogram_chunk_{chunk_idx:04d}.png'\n",
    "            )\n",
    "            \n",
    "            # Create and save spectrogram\n",
    "            create_spectrogram(y, sr, output_path, device)\n",
    "            \n",
    "            print(f\"Processed chunk {chunk_idx + 1}/{total_chunks}\")\n",
    "            \n",
    "            # Explicit memory cleanup\n",
    "            del y\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {chunk_idx}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = \"/home/ahmed/Task-Aware-audio-coding-perceptual/Data/dataset/S02_U03.CH1.wav\"\n",
    "    process_audio_file(input_file, max_duration=3600, chunk_duration=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed audio saved as: reconstructed_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from PIL import Image\n",
    "\n",
    "def load_spectrogram_image(image_path):\n",
    "    \"\"\"Load the spectrogram image and convert it to a magnitude spectrogram.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert(\"L\")  # Convert to grayscale\n",
    "    spectrogram = np.array(img)\n",
    "\n",
    "    # Normalize the spectrogram to the range [0, 1]\n",
    "    spectrogram = spectrogram / 255.0\n",
    "    \n",
    "    # Convert to dB scale\n",
    "    spectrogram_db = librosa.amplitude_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "    return spectrogram_db\n",
    "\n",
    "def reconstruct_audio(spectrogram_db, sr, n_fft=2048, hop_length=512):\n",
    "    \"\"\"Reconstruct the audio signal from the spectrogram using Griffin-Lim algorithm.\"\"\"\n",
    "    # Convert back to amplitude\n",
    "    S = librosa.db_to_amplitude(spectrogram_db)  \n",
    "\n",
    "    # Use Griffin-Lim algorithm for reconstruction\n",
    "    y_reconstructed = librosa.griffinlim(S, n_iter=32, hop_length=hop_length)\n",
    "\n",
    "    return y_reconstructed\n",
    "\n",
    "def main():\n",
    "    # Path to your spectrogram image\n",
    "    spectrogram_image_path = './Data/clean_images/spectrograms_S02_P05/spectrogram_chunk_0000.png'  # Replace with your spectrogram image path\n",
    "    sr = 22050  # Set your desired sample rate (this should match your original audio file)\n",
    "\n",
    "    # Load the spectrogram from the image\n",
    "    spectrogram_db = load_spectrogram_image(spectrogram_image_path)\n",
    "\n",
    "    # Reconstruct audio from the spectrogram\n",
    "    y_reconstructed = reconstruct_audio(spectrogram_db, sr)\n",
    "\n",
    "    # Save the reconstructed audio to a file\n",
    "    output_audio_file = 'reconstructed_audio.wav'\n",
    "    sf.write(output_audio_file, y_reconstructed, sr)\n",
    "\n",
    "    print(\"Reconstructed audio saved as:\", output_audio_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from librosa.feature.inverse import mel_to_audio\n",
    "import scipy.signal\n",
    "\n",
    "def create_output_directory(base_path, session_id, speaker):\n",
    "    \"\"\"Create output directories for spectrograms and reconstructed audio.\"\"\"\n",
    "    spec_dir = os.path.join(base_path, f'spectrograms_{session_id}_{speaker}_U05.CH3')\n",
    "    audio_dir = os.path.join(base_path, f'reconstructed_audio_{session_id}_{speaker}_U05.CH3')\n",
    "    os.makedirs(spec_dir, exist_ok=True)\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "    return spec_dir, audio_dir\n",
    "\n",
    "def load_audio_chunk(file_path, start_time_str, end_time_str):\n",
    "    \"\"\"Load a chunk of audio from the file using timestamp strings.\"\"\"\n",
    "    def timestamp_to_seconds(timestamp):\n",
    "        h, m, s = timestamp.split(':')\n",
    "        return float(h) * 3600 + float(m) * 60 + float(s)\n",
    "    \n",
    "    start_seconds = timestamp_to_seconds(start_time_str)\n",
    "    end_seconds = timestamp_to_seconds(end_time_str)\n",
    "    duration = end_seconds - start_seconds\n",
    "    \n",
    "    y, sr = librosa.load(file_path, offset=start_seconds, duration=duration)\n",
    "    return y, sr\n",
    "\n",
    "def create_spectrogram(y, sr):\n",
    "    \"\"\"Create a spectrogram for the given audio chunk and return the STFT matrix.\"\"\"\n",
    "    # Compute STFT\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    \n",
    "    # Compute the complex STFT matrix\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    \n",
    "    # Convert to dB-scale spectrogram\n",
    "    D_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    \n",
    "    return D, D_db, n_fft, hop_length\n",
    "\n",
    "def save_spectrogram_plot(D_db, sr, output_path):\n",
    "    \"\"\"Save the spectrogram visualization.\"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(D_db, y_axis='log', x_axis='time', sr=sr)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def reconstruct_audio(D, sr, hop_length, output_path):\n",
    "    \"\"\"Reconstruct audio from STFT matrix and save to file.\"\"\"\n",
    "    # Perform inverse STFT\n",
    "    y_reconstructed = librosa.istft(D, hop_length=hop_length)\n",
    "    \n",
    "    # Normalize audio\n",
    "    y_reconstructed = librosa.util.normalize(y_reconstructed)\n",
    "    \n",
    "    # Save reconstructed audio\n",
    "    sf.write(output_path, y_reconstructed, sr)\n",
    "    \n",
    "    return y_reconstructed\n",
    "\n",
    "def process_audio_file(audio_file, json_file, target_speaker):\n",
    "    \"\"\"Process an audio file into spectrograms and reconstruct audio.\"\"\"\n",
    "    base_path = os.path.dirname(audio_file)\n",
    "    \n",
    "    # Load JSON data\n",
    "    with open(json_file, 'r') as f:\n",
    "        segments = json.load(f)\n",
    "    \n",
    "    # Filter segments for target speaker\n",
    "    speaker_segments = [seg for seg in segments if seg['speaker'] == target_speaker]\n",
    "    \n",
    "    if speaker_segments:\n",
    "        session_id = speaker_segments[0]['session_id']\n",
    "        spec_dir, audio_dir = create_output_directory(base_path, session_id, target_speaker)\n",
    "    else:\n",
    "        print(f\"No segments found for speaker {target_speaker}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing {len(speaker_segments)} segments for speaker {target_speaker}\")\n",
    "    \n",
    "    # Process each segment\n",
    "    for i, segment in enumerate(speaker_segments):\n",
    "        try:\n",
    "            # Load audio chunk\n",
    "            y, sr = load_audio_chunk(\n",
    "                audio_file,\n",
    "                segment['start_time'],\n",
    "                segment['end_time']\n",
    "            )\n",
    "            \n",
    "            # Generate output filenames\n",
    "            spec_output = os.path.join(\n",
    "                spec_dir,\n",
    "                f\"spectrogram_{target_speaker}_{i:04d}_{segment['start_time'].replace(':', '_')}.png\"\n",
    "            )\n",
    "            audio_output = os.path.join(\n",
    "                audio_dir,\n",
    "                f\"reconstructed_{target_speaker}_{i:04d}_{segment['start_time'].replace(':', '_')}.wav\"\n",
    "            )\n",
    "            \n",
    "            # Create spectrogram and get STFT matrix\n",
    "            D, D_db, n_fft, hop_length = create_spectrogram(y, sr)\n",
    "            \n",
    "            # Save spectrogram visualization\n",
    "            save_spectrogram_plot(D_db, sr, spec_output)\n",
    "            \n",
    "            # Reconstruct and save audio\n",
    "            reconstruct_audio(D, sr, hop_length, audio_output)\n",
    "            \n",
    "            print(f\"Processed segment {i + 1}/{len(speaker_segments)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing segment {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = \"/home/ahmed/Dataset/S02_U05.CH3.wav\"\n",
    "    json_file = \"/home/ahmed/Dataset/S02.json\"\n",
    "    target_speaker = \"P08\"\n",
    "    \n",
    "    process_audio_file(audio_file, json_file, target_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spectrogram_P08_0971_02_17_29.77.png...\n",
      "Error processing spectrogram_P08_0971_02_17_29.77.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0871_02_05_05.51.png...\n",
      "Error processing spectrogram_P08_0871_02_05_05.51.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0851_02_02_27.51.png...\n",
      "Error processing spectrogram_P08_0851_02_02_27.51.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0978_02_18_06.80.png...\n",
      "Error processing spectrogram_P08_0978_02_18_06.80.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0901_02_09_40.49.png...\n",
      "Error processing spectrogram_P08_0901_02_09_40.49.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0880_02_05_50.93.png...\n",
      "Error processing spectrogram_P08_0880_02_05_50.93.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0930_02_13_27.09.png...\n",
      "Error processing spectrogram_P08_0930_02_13_27.09.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0883_02_06_03.81.png...\n",
      "Error processing spectrogram_P08_0883_02_06_03.81.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0981_02_18_23.02.png...\n",
      "Error processing spectrogram_P08_0981_02_18_23.02.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0990_02_19_46.56.png...\n",
      "Error processing spectrogram_P08_0990_02_19_46.56.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0964_02_16_15.69.png...\n",
      "Error processing spectrogram_P08_0964_02_16_15.69.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1012_02_22_26.98.png...\n",
      "Error processing spectrogram_P08_1012_02_22_26.98.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0962_02_16_06.89.png...\n",
      "Error processing spectrogram_P08_0962_02_16_06.89.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0934_02_13_44.01.png...\n",
      "Error processing spectrogram_P08_0934_02_13_44.01.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0925_02_12_35.17.png...\n",
      "Error processing spectrogram_P08_0925_02_12_35.17.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0995_02_20_30.26.png...\n",
      "Error processing spectrogram_P08_0995_02_20_30.26.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0874_02_05_23.11.png...\n",
      "Error processing spectrogram_P08_0874_02_05_23.11.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1039_02_26_04.90.png...\n",
      "Error processing spectrogram_P08_1039_02_26_04.90.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0918_02_12_05.27.png...\n",
      "Error processing spectrogram_P08_0918_02_12_05.27.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1014_02_22_43.36.png...\n",
      "Error processing spectrogram_P08_1014_02_22_43.36.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0919_02_12_12.13.png...\n",
      "Error processing spectrogram_P08_0919_02_12_12.13.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0939_02_14_11.49.png...\n",
      "Error processing spectrogram_P08_0939_02_14_11.49.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1011_02_22_21.36.png...\n",
      "Error processing spectrogram_P08_1011_02_22_21.36.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0983_02_18_44.28.png...\n",
      "Error processing spectrogram_P08_0983_02_18_44.28.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1018_02_23_02.32.png...\n",
      "Error processing spectrogram_P08_1018_02_23_02.32.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0868_02_04_54.23.png...\n",
      "Error processing spectrogram_P08_0868_02_04_54.23.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0931_02_13_30.73.png...\n",
      "Error processing spectrogram_P08_0931_02_13_30.73.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0877_02_05_36.37.png...\n",
      "Error processing spectrogram_P08_0877_02_05_36.37.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1013_02_22_34.04.png...\n",
      "Error processing spectrogram_P08_1013_02_22_34.04.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0982_02_18_27.22.png...\n",
      "Error processing spectrogram_P08_0982_02_18_27.22.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1010_02_22_13.92.png...\n",
      "Error processing spectrogram_P08_1010_02_22_13.92.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0879_02_05_46.26.png...\n",
      "Error processing spectrogram_P08_0879_02_05_46.26.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0857_02_03_12.33.png...\n",
      "Error processing spectrogram_P08_0857_02_03_12.33.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1026_02_23_48.92.png...\n",
      "Error processing spectrogram_P08_1026_02_23_48.92.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1003_02_21_24.26.png...\n",
      "Error processing spectrogram_P08_1003_02_21_24.26.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1015_02_22_49.00.png...\n",
      "Error processing spectrogram_P08_1015_02_22_49.00.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1037_02_25_54.72.png...\n",
      "Error processing spectrogram_P08_1037_02_25_54.72.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0950_02_14_55.69.png...\n",
      "Error processing spectrogram_P08_0950_02_14_55.69.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0922_02_12_23.93.png...\n",
      "Error processing spectrogram_P08_0922_02_12_23.93.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0899_02_09_33.25.png...\n",
      "Error processing spectrogram_P08_0899_02_09_33.25.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0875_02_05_29.29.png...\n",
      "Error processing spectrogram_P08_0875_02_05_29.29.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0998_02_20_54.96.png...\n",
      "Error processing spectrogram_P08_0998_02_20_54.96.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0909_02_11_09.07.png...\n",
      "Error processing spectrogram_P08_0909_02_11_09.07.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0942_02_14_23.13.png...\n",
      "Error processing spectrogram_P08_0942_02_14_23.13.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0923_02_12_29.99.png...\n",
      "Error processing spectrogram_P08_0923_02_12_29.99.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1001_02_21_10.98.png...\n",
      "Error processing spectrogram_P08_1001_02_21_10.98.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0951_02_15_01.47.png...\n",
      "Error processing spectrogram_P08_0951_02_15_01.47.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0987_02_19_08.26.png...\n",
      "Error processing spectrogram_P08_0987_02_19_08.26.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0890_02_08_16.43.png...\n",
      "Error processing spectrogram_P08_0890_02_08_16.43.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0988_02_19_22.70.png...\n",
      "Error processing spectrogram_P08_0988_02_19_22.70.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0952_02_15_17.71.png...\n",
      "Error processing spectrogram_P08_0952_02_15_17.71.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0888_02_07_14.63.png...\n",
      "Error processing spectrogram_P08_0888_02_07_14.63.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0974_02_17_48.05.png...\n",
      "Error processing spectrogram_P08_0974_02_17_48.05.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1006_02_21_49.46.png...\n",
      "Error processing spectrogram_P08_1006_02_21_49.46.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0861_02_03_58.65.png...\n",
      "Error processing spectrogram_P08_0861_02_03_58.65.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1025_02_23_24.68.png...\n",
      "Error processing spectrogram_P08_1025_02_23_24.68.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1033_02_24_52.88.png...\n",
      "Error processing spectrogram_P08_1033_02_24_52.88.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0852_02_02_33.21.png...\n",
      "Error processing spectrogram_P08_0852_02_02_33.21.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0936_02_13_58.83.png...\n",
      "Error processing spectrogram_P08_0936_02_13_58.83.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1007_02_21_58.08.png...\n",
      "Error processing spectrogram_P08_1007_02_21_58.08.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0940_02_14_13.59.png...\n",
      "Error processing spectrogram_P08_0940_02_14_13.59.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0991_02_19_50.84.png...\n",
      "Error processing spectrogram_P08_0991_02_19_50.84.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0914_02_11_47.03.png...\n",
      "Error processing spectrogram_P08_0914_02_11_47.03.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1005_02_21_44.80.png...\n",
      "Error processing spectrogram_P08_1005_02_21_44.80.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0912_02_11_37.87.png...\n",
      "Error processing spectrogram_P08_0912_02_11_37.87.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0897_02_09_23.03.png...\n",
      "Error processing spectrogram_P08_0897_02_09_23.03.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1000_02_21_06.80.png...\n",
      "Error processing spectrogram_P08_1000_02_21_06.80.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0856_02_03_05.39.png...\n",
      "Error processing spectrogram_P08_0856_02_03_05.39.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0938_02_14_05.23.png...\n",
      "Error processing spectrogram_P08_0938_02_14_05.23.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0935_02_13_52.71.png...\n",
      "Error processing spectrogram_P08_0935_02_13_52.71.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0905_02_10_28.29.png...\n",
      "Error processing spectrogram_P08_0905_02_10_28.29.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1045_02_26_57.62.png...\n",
      "Error processing spectrogram_P08_1045_02_26_57.62.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0886_02_06_48.79.png...\n",
      "Error processing spectrogram_P08_0886_02_06_48.79.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0924_02_12_31.89.png...\n",
      "Error processing spectrogram_P08_0924_02_12_31.89.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1016_02_22_55.16.png...\n",
      "Error processing spectrogram_P08_1016_02_22_55.16.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0895_02_09_16.55.png...\n",
      "Error processing spectrogram_P08_0895_02_09_16.55.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1046_02_27_08.44.png...\n",
      "Error processing spectrogram_P08_1046_02_27_08.44.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0954_02_15_25.81.png...\n",
      "Error processing spectrogram_P08_0954_02_15_25.81.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0966_02_16_31.27.png...\n",
      "Error processing spectrogram_P08_0966_02_16_31.27.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0945_02_14_33.79.png...\n",
      "Error processing spectrogram_P08_0945_02_14_33.79.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1044_02_26_54.00.png...\n",
      "Error processing spectrogram_P08_1044_02_26_54.00.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0994_02_20_23.64.png...\n",
      "Error processing spectrogram_P08_0994_02_20_23.64.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0926_02_12_48.25.png...\n",
      "Error processing spectrogram_P08_0926_02_12_48.25.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0975_02_17_56.09.png...\n",
      "Error processing spectrogram_P08_0975_02_17_56.09.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0862_02_04_08.09.png...\n",
      "Error processing spectrogram_P08_0862_02_04_08.09.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1019_02_23_04.82.png...\n",
      "Error processing spectrogram_P08_1019_02_23_04.82.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0865_02_04_36.13.png...\n",
      "Error processing spectrogram_P08_0865_02_04_36.13.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0985_02_18_54.00.png...\n",
      "Error processing spectrogram_P08_0985_02_18_54.00.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0980_02_18_18.18.png...\n",
      "Error processing spectrogram_P08_0980_02_18_18.18.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0866_02_04_39.75.png...\n",
      "Error processing spectrogram_P08_0866_02_04_39.75.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0953_02_15_21.83.png...\n",
      "Error processing spectrogram_P08_0953_02_15_21.83.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0944_02_14_29.19.png...\n",
      "Error processing spectrogram_P08_0944_02_14_29.19.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0910_02_11_16.63.png...\n",
      "Error processing spectrogram_P08_0910_02_11_16.63.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0881_02_05_55.21.png...\n",
      "Error processing spectrogram_P08_0881_02_05_55.21.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1021_02_23_11.04.png...\n",
      "Error processing spectrogram_P08_1021_02_23_11.04.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0979_02_18_10.78.png...\n",
      "Error processing spectrogram_P08_0979_02_18_10.78.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0893_02_09_04.65.png...\n",
      "Error processing spectrogram_P08_0893_02_09_04.65.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0941_02_14_15.61.png...\n",
      "Error processing spectrogram_P08_0941_02_14_15.61.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0997_02_20_41.36.png...\n",
      "Error processing spectrogram_P08_0997_02_20_41.36.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0958_02_15_45.23.png...\n",
      "Error processing spectrogram_P08_0958_02_15_45.23.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0853_02_02_48.11.png...\n",
      "Error processing spectrogram_P08_0853_02_02_48.11.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1047_02_27_14.68.png...\n",
      "Error processing spectrogram_P08_1047_02_27_14.68.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0891_02_08_34.07.png...\n",
      "Error processing spectrogram_P08_0891_02_08_34.07.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0972_02_17_34.93.png...\n",
      "Error processing spectrogram_P08_0972_02_17_34.93.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0913_02_11_43.39.png...\n",
      "Error processing spectrogram_P08_0913_02_11_43.39.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1027_02_24_00.70.png...\n",
      "Error processing spectrogram_P08_1027_02_24_00.70.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1035_02_25_08.46.png...\n",
      "Error processing spectrogram_P08_1035_02_25_08.46.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0943_02_14_26.85.png...\n",
      "Error processing spectrogram_P08_0943_02_14_26.85.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1030_02_24_37.76.png...\n",
      "Error processing spectrogram_P08_1030_02_24_37.76.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0894_02_09_09.95.png...\n",
      "Error processing spectrogram_P08_0894_02_09_09.95.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0977_02_18_03.69.png...\n",
      "Error processing spectrogram_P08_0977_02_18_03.69.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0908_02_10_51.67.png...\n",
      "Error processing spectrogram_P08_0908_02_10_51.67.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0858_02_03_32.09.png...\n",
      "Error processing spectrogram_P08_0858_02_03_32.09.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0889_02_07_27.87.png...\n",
      "Error processing spectrogram_P08_0889_02_07_27.87.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0963_02_16_11.65.png...\n",
      "Error processing spectrogram_P08_0963_02_16_11.65.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0933_02_13_41.09.png...\n",
      "Error processing spectrogram_P08_0933_02_13_41.09.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0870_02_05_02.79.png...\n",
      "Error processing spectrogram_P08_0870_02_05_02.79.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0902_02_09_46.99.png...\n",
      "Error processing spectrogram_P08_0902_02_09_46.99.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1034_02_25_04.86.png...\n",
      "Error processing spectrogram_P08_1034_02_25_04.86.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1050_02_28_11.64.png...\n",
      "Error processing spectrogram_P08_1050_02_28_11.64.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1024_02_23_19.82.png...\n",
      "Error processing spectrogram_P08_1024_02_23_19.82.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1028_02_24_07.06.png...\n",
      "Error processing spectrogram_P08_1028_02_24_07.06.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0957_02_15_41.27.png...\n",
      "Error processing spectrogram_P08_0957_02_15_41.27.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0947_02_14_42.27.png...\n",
      "Error processing spectrogram_P08_0947_02_14_42.27.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0932_02_13_33.65.png...\n",
      "Error processing spectrogram_P08_0932_02_13_33.65.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1017_02_22_58.88.png...\n",
      "Error processing spectrogram_P08_1017_02_22_58.88.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0976_02_17_57.99.png...\n",
      "Error processing spectrogram_P08_0976_02_17_57.99.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0906_02_10_33.77.png...\n",
      "Error processing spectrogram_P08_0906_02_10_33.77.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0911_02_11_23.03.png...\n",
      "Error processing spectrogram_P08_0911_02_11_23.03.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1029_02_24_12.76.png...\n",
      "Error processing spectrogram_P08_1029_02_24_12.76.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0955_02_15_31.91.png...\n",
      "Error processing spectrogram_P08_0955_02_15_31.91.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0973_02_17_45.33.png...\n",
      "Error processing spectrogram_P08_0973_02_17_45.33.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0968_02_16_47.89.png...\n",
      "Error processing spectrogram_P08_0968_02_16_47.89.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0956_02_15_37.17.png...\n",
      "Error processing spectrogram_P08_0956_02_15_37.17.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0915_02_11_52.05.png...\n",
      "Error processing spectrogram_P08_0915_02_11_52.05.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1022_02_23_15.58.png...\n",
      "Error processing spectrogram_P08_1022_02_23_15.58.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0970_02_17_12.81.png...\n",
      "Error processing spectrogram_P08_0970_02_17_12.81.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1042_02_26_41.38.png...\n",
      "Error processing spectrogram_P08_1042_02_26_41.38.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0885_02_06_36.07.png...\n",
      "Error processing spectrogram_P08_0885_02_06_36.07.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0967_02_16_38.09.png...\n",
      "Error processing spectrogram_P08_0967_02_16_38.09.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0921_02_12_18.83.png...\n",
      "Error processing spectrogram_P08_0921_02_12_18.83.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1009_02_22_07.70.png...\n",
      "Error processing spectrogram_P08_1009_02_22_07.70.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0965_02_16_19.29.png...\n",
      "Error processing spectrogram_P08_0965_02_16_19.29.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0859_02_03_36.25.png...\n",
      "Error processing spectrogram_P08_0859_02_03_36.25.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1038_02_26_02.08.png...\n",
      "Error processing spectrogram_P08_1038_02_26_02.08.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0898_02_09_31.69.png...\n",
      "Error processing spectrogram_P08_0898_02_09_31.69.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1031_02_24_40.18.png...\n",
      "Error processing spectrogram_P08_1031_02_24_40.18.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0884_02_06_08.45.png...\n",
      "Error processing spectrogram_P08_0884_02_06_08.45.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0992_02_19_58.64.png...\n",
      "Error processing spectrogram_P08_0992_02_19_58.64.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1036_02_25_34.48.png...\n",
      "Error processing spectrogram_P08_1036_02_25_34.48.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0855_02_03_02.75.png...\n",
      "Error processing spectrogram_P08_0855_02_03_02.75.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0959_02_15_48.47.png...\n",
      "Error processing spectrogram_P08_0959_02_15_48.47.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0903_02_09_50.29.png...\n",
      "Error processing spectrogram_P08_0903_02_09_50.29.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1048_02_27_19.60.png...\n",
      "Error processing spectrogram_P08_1048_02_27_19.60.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1049_02_27_57.58.png...\n",
      "Error processing spectrogram_P08_1049_02_27_57.58.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1041_02_26_20.78.png...\n",
      "Error processing spectrogram_P08_1041_02_26_20.78.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1002_02_21_22.96.png...\n",
      "Error processing spectrogram_P08_1002_02_21_22.96.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0984_02_18_49.16.png...\n",
      "Error processing spectrogram_P08_0984_02_18_49.16.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1023_02_23_17.06.png...\n",
      "Error processing spectrogram_P08_1023_02_23_17.06.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0996_02_20_34.46.png...\n",
      "Error processing spectrogram_P08_0996_02_20_34.46.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1004_02_21_40.52.png...\n",
      "Error processing spectrogram_P08_1004_02_21_40.52.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0920_02_12_17.05.png...\n",
      "Error processing spectrogram_P08_0920_02_12_17.05.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0969_02_16_59.31.png...\n",
      "Error processing spectrogram_P08_0969_02_16_59.31.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1043_02_26_49.62.png...\n",
      "Error processing spectrogram_P08_1043_02_26_49.62.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0882_02_05_59.17.png...\n",
      "Error processing spectrogram_P08_0882_02_05_59.17.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0867_02_04_46.75.png...\n",
      "Error processing spectrogram_P08_0867_02_04_46.75.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1040_02_26_08.06.png...\n",
      "Error processing spectrogram_P08_1040_02_26_08.06.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0989_02_19_33.54.png...\n",
      "Error processing spectrogram_P08_0989_02_19_33.54.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0873_02_05_17.11.png...\n",
      "Error processing spectrogram_P08_0873_02_05_17.11.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0864_02_04_25.41.png...\n",
      "Error processing spectrogram_P08_0864_02_04_25.41.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0927_02_12_55.79.png...\n",
      "Error processing spectrogram_P08_0927_02_12_55.79.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1020_02_23_08.82.png...\n",
      "Error processing spectrogram_P08_1020_02_23_08.82.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0949_02_14_48.69.png...\n",
      "Error processing spectrogram_P08_0949_02_14_48.69.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0863_02_04_12.57.png...\n",
      "Error processing spectrogram_P08_0863_02_04_12.57.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0960_02_15_54.95.png...\n",
      "Error processing spectrogram_P08_0960_02_15_54.95.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0878_02_05_42.03.png...\n",
      "Error processing spectrogram_P08_0878_02_05_42.03.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0916_02_11_54.73.png...\n",
      "Error processing spectrogram_P08_0916_02_11_54.73.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0948_02_14_45.75.png...\n",
      "Error processing spectrogram_P08_0948_02_14_45.75.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0999_02_20_59.62.png...\n",
      "Error processing spectrogram_P08_0999_02_20_59.62.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0854_02_02_58.55.png...\n",
      "Error processing spectrogram_P08_0854_02_02_58.55.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0917_02_12_00.95.png...\n",
      "Error processing spectrogram_P08_0917_02_12_00.95.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1008_02_22_00.38.png...\n",
      "Error processing spectrogram_P08_1008_02_22_00.38.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0887_02_07_00.07.png...\n",
      "Error processing spectrogram_P08_0887_02_07_00.07.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0876_02_05_33.13.png...\n",
      "Error processing spectrogram_P08_0876_02_05_33.13.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_1032_02_24_47.90.png...\n",
      "Error processing spectrogram_P08_1032_02_24_47.90.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0928_02_13_07.07.png...\n",
      "Error processing spectrogram_P08_0928_02_13_07.07.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0907_02_10_41.37.png...\n",
      "Error processing spectrogram_P08_0907_02_10_41.37.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0986_02_18_56.44.png...\n",
      "Error processing spectrogram_P08_0986_02_18_56.44.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0860_02_03_51.61.png...\n",
      "Error processing spectrogram_P08_0860_02_03_51.61.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0993_02_20_11.08.png...\n",
      "Error processing spectrogram_P08_0993_02_20_11.08.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0929_02_13_10.35.png...\n",
      "Error processing spectrogram_P08_0929_02_13_10.35.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0946_02_14_38.03.png...\n",
      "Error processing spectrogram_P08_0946_02_14_38.03.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0961_02_16_00.11.png...\n",
      "Error processing spectrogram_P08_0961_02_16_00.11.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0937_02_14_00.26.png...\n",
      "Error processing spectrogram_P08_0937_02_14_00.26.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0896_02_09_19.73.png...\n",
      "Error processing spectrogram_P08_0896_02_09_19.73.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0869_02_04_59.37.png...\n",
      "Error processing spectrogram_P08_0869_02_04_59.37.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0872_02_05_13.25.png...\n",
      "Error processing spectrogram_P08_0872_02_05_13.25.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0904_02_10_13.37.png...\n",
      "Error processing spectrogram_P08_0904_02_10_13.37.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0892_02_08_57.81.png...\n",
      "Error processing spectrogram_P08_0892_02_08_57.81.png: Target size (578) must be at least input size (2048)\n",
      "Processing spectrogram_P08_0900_02_09_37.19.png...\n",
      "Error processing spectrogram_P08_0900_02_09_37.19.png: Target size (578) must be at least input size (2048)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from librosa.feature.inverse import griffinlim\n",
    "import cv2\n",
    "\n",
    "def load_spectrogram_image(image_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess a spectrogram image, converting it back to a format suitable \n",
    "    for audio reconstruction.\n",
    "    \"\"\"\n",
    "    # Load image and convert to grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Remove axes and colorbar by cropping (adjust these values based on your images)\n",
    "    # You'll need to adjust these crop values based on your specific spectrogram images\n",
    "    height, width = img.shape\n",
    "    img = img[80:height-30, 80:width-60]  # Adjust these values based on your images\n",
    "    \n",
    "    # Normalize to 0-1 range\n",
    "    img_normalized = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Invert the colors (assuming darker means higher intensity)\n",
    "    img_normalized = 1 - img_normalized\n",
    "    \n",
    "    # Convert from dB scale back to linear scale\n",
    "    spec = librosa.db_to_amplitude(img_normalized * 80 - 80)  # Adjust scaling factors as needed\n",
    "    \n",
    "    return spec\n",
    "\n",
    "def reconstruct_audio_from_spectrogram(spec, n_iter=32):\n",
    "    \"\"\"\n",
    "    Reconstruct audio from a spectrogram using Griffin-Lim algorithm.\n",
    "    \"\"\"\n",
    "    # Apply Griffin-Lim algorithm to recover audio\n",
    "    y_reconstructed = griffinlim(\n",
    "        spec,\n",
    "        n_iter=n_iter,\n",
    "        hop_length=512,\n",
    "        win_length=2048\n",
    "    )\n",
    "    \n",
    "    # Normalize audio\n",
    "    y_reconstructed = librosa.util.normalize(y_reconstructed)\n",
    "    \n",
    "    return y_reconstructed\n",
    "\n",
    "def process_spectrogram_directory(input_dir, output_dir, sr=22050):\n",
    "    \"\"\"\n",
    "    Process all spectrogram images in a directory and convert them to audio files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each spectrogram image\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                print(f\"Processing {filename}...\")\n",
    "                \n",
    "                # Load and process spectrogram\n",
    "                image_path = os.path.join(input_dir, filename)\n",
    "                spec = load_spectrogram_image(image_path)\n",
    "                \n",
    "                # Reconstruct audio\n",
    "                audio = reconstruct_audio_from_spectrogram(spec)\n",
    "                \n",
    "                # Save audio file\n",
    "                output_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}.wav\")\n",
    "                sf.write(output_path, audio, sr)\n",
    "                \n",
    "                print(f\"Successfully created {output_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_directory = \"/home/ahmed/Task-Aware-audio-coding-perceptual/Data/updated/clean_images/spectrograms_S02_P08/Test\"  # Replace with your spectrogram directory\n",
    "    output_directory = \"/home/ahmed/Task-Aware-audio-coding-perceptual/Data/reconstruction\"  # Replace with your desired output directory\n",
    "    \n",
    "    process_spectrogram_directory(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from librosa.feature.inverse import griffinlim\n",
    "import cv2\n",
    "\n",
    "def load_spectrogram_image(image_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess a spectrogram image, converting it back to a format suitable \n",
    "    for audio reconstruction.\n",
    "    \"\"\"\n",
    "    # Load image and convert to grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Remove axes and colorbar by cropping\n",
    "    height, width = img.shape\n",
    "    img = img[80:height-30, 80:width-60]  # Adjust these values based on your images\n",
    "    \n",
    "    # Resize the image to match expected STFT dimensions\n",
    "    # Making height 1025 (n_fft // 2 + 1) for 2048 FFT size\n",
    "    target_height = 513  # For 1024 FFT size\n",
    "    target_width = width  # Keep original width\n",
    "    img = cv2.resize(img, (target_width, target_height))\n",
    "    \n",
    "    # Normalize to 0-1 range\n",
    "    img_normalized = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Invert the colors (assuming darker means higher intensity)\n",
    "    img_normalized = 1 - img_normalized\n",
    "    \n",
    "    # Convert from dB scale back to linear scale\n",
    "    spec = librosa.db_to_amplitude(img_normalized * 80 - 80)  # Adjust scaling factors as needed\n",
    "    \n",
    "    return spec\n",
    "\n",
    "def reconstruct_audio_from_spectrogram(spec, n_iter=32):\n",
    "    \"\"\"\n",
    "    Reconstruct audio from a spectrogram using Griffin-Lim algorithm.\n",
    "    \"\"\"\n",
    "    # Use smaller FFT size\n",
    "    n_fft = 1024\n",
    "    hop_length = n_fft // 4  # 256 for 1024 FFT size\n",
    "    \n",
    "    # Apply Griffin-Lim algorithm to recover audio\n",
    "    y_reconstructed = griffinlim(\n",
    "        spec,\n",
    "        n_iter=n_iter,\n",
    "        hop_length=hop_length,\n",
    "        win_length=n_fft,\n",
    "        n_fft=n_fft\n",
    "    )\n",
    "    \n",
    "    # Normalize audio\n",
    "    y_reconstructed = librosa.util.normalize(y_reconstructed)\n",
    "    \n",
    "    return y_reconstructed\n",
    "\n",
    "def process_spectrogram_directory(input_dir, output_dir, sr=22050):\n",
    "    \"\"\"\n",
    "    Process all spectrogram images in a directory and convert them to audio files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each spectrogram image\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                print(f\"Processing {filename}...\")\n",
    "                \n",
    "                # Load and process spectrogram\n",
    "                image_path = os.path.join(input_dir, filename)\n",
    "                spec = load_spectrogram_image(image_path)\n",
    "                \n",
    "                # Print shape for debugging\n",
    "                print(f\"Spectrogram shape: {spec.shape}\")\n",
    "                \n",
    "                # Reconstruct audio\n",
    "                audio = reconstruct_audio_from_spectrogram(spec)\n",
    "                \n",
    "                # Save audio file\n",
    "                output_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}.wav\")\n",
    "                sf.write(output_path, audio, sr)\n",
    "                \n",
    "                print(f\"Successfully created {output_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "                print(f\"Full error: \", e.__class__.__name__)\n",
    "                continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_directory = \"/home/ahmed/Task-Aware-audio-coding-perceptual/Data/updated/clean_images/spectrograms_S02_P08/Test\"  # Replace with your spectrogram directory\n",
    "    output_directory = \"/home/ahmed/Task-Aware-audio-coding-perceptual/Data/reconstruction\"  # Replace with your desired output directory\n",
    "    \n",
    "    process_spectrogram_directory(input_directory, output_directory)"
=======
    "/home/ahsan/Ahsan/PhD work/AAAI_2025_PAPER/audio-encoders-pytorch/audio_encoders_pytorch"
>>>>>>> c275dbf7ac0ebf47403d57d04a12f0d92826c478
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
